{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "\n",
        " A parameter is a variable , it is use to pass information to a function , method or procedure . Parameter is the variable in the function definition.\n",
        "  Argument is the actual value you pass when calling the function.\n",
        "\n"
      ],
      "metadata": {
        "id": "iLzxz3ZxqxWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. What is correlation?\n",
        "What does negative correlation mean?\n",
        "   \n",
        "   Correlation is a statistical measure that describes how two variables move in relation to each other. If there's no predictable relationship, they are uncorrelated. Correlation is usually measured with a number between -1 and 1 .\n",
        "\n",
        "   A negative correlation means that as one variable increases, the other tends to decrease, and vice versa.\n",
        "   -0.5: Moderate negative correlation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bMSnJTqLsrma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3 . Define Machine Learning. What are the main components in Machine Learning?\n",
        "     \n",
        "   Machine Learning is a subset of artificial intelligence that focuses on developing algorithms and statistical models that enable computers to learn from data and make predictions or decisions without being explicitly programmed for every task. The goal is for the system to improve its performance over time as it is exposed to more data.\n",
        "   The foundation of any ML model.\n",
        "  \n",
        "  Importance of ML :\n",
        "                    \n",
        "  Includes input features and labels/targets  in supervised learning.\n",
        "   A mathematical or computational structure that learns patterns from data.\n",
        "   The individual measurable properties or characteristics of the data.The process of feeding data into the ML model and allowing it to learn patterns.\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P85GU2iavXxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "  The loss value is a numerical measure of how far off your model’s predictions are from the actual results. It's essentially a signal that tells you how well your model is learning. .\n",
        "\n",
        " During training, the goal is to minimize the loss.\n",
        "A decreasing loss usually means the model is learning and improving .You can compare different models or different versions of the same model based on their loss values.\n",
        "\n"
      ],
      "metadata": {
        "id": "87j-VHL9xa3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 .What are continuous and categorical variables?\n",
        "   \n",
        "   Continuous Variables are quantitative variables that can take on any value within a range. They are typically measured, not counted.\n",
        "\n",
        "   Examples:\n",
        "\n",
        "Height (e.g., 170.5 cm)\n",
        "  \n",
        "  Categorical Variables are qualitative variables that represent groups or categories. They describe qualities or characteristics, not amounts.\n",
        "\n",
        "  Examples:\n",
        "\n",
        "Gender (e.g., Male, Female, Non-binary)\n"
      ],
      "metadata": {
        "id": "6m61mc-PyPMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 .How do we handle categorical variables in Machine Learning? What are the common t\n",
        "echniques?\n",
        "  \n",
        "  Handling categorical variables is a big part of preparing data for machine learning models, especially because most ML algorithms expect numerical input. In this the most common techniques used to convert categorical data into something models can understand .\n",
        "\n",
        "\n",
        "  Label Encoding\n",
        "Assigns each category a unique integer .\n",
        "\n",
        "imple and fast.\n",
        "\n",
        "Good for ordinal data .\n",
        "\n",
        "One-Hot Encoding\n",
        "Creates binary columns for each category .\n",
        "\n",
        "dinal Encoding\n",
        "Assigns integers respecting the order of categories.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T6Vyq1QXzsJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What do you mean by training and testing a dataset?\n",
        "   \n",
        "   When building a machine learning model, we need to check how well it learns and how well it performs on unseen data. To do this, we split the dataset into two parts -\n",
        "\n",
        "   1. Training Set\n",
        "This is the part of the data we use to train the model.\n",
        "\n",
        "    the model learns patterns and relationships from this data.\n",
        "\n",
        "  2. Testing Set\n",
        "      This is the data we use to evaluate the model after training.\n",
        "\n",
        "         It checks how well the model can predict outcomes for new, unseen data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7l7ef5v204l7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8 .What is sklearn.preprocessing?\n",
        "\n",
        "sklearn.preprocessing is a module in Scikit-learn that provides tools to prepare your data before training a model.\n",
        "\n",
        "In ML, raw data often needs to be cleaned, scaled, or transformed into a format that models can understand"
      ],
      "metadata": {
        "id": "3TdDx4Bk2AIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9 .What is a Test set?\n",
        "\n",
        "The test set is a portion of your dataset that you set aside and do not use during training. After your model is trained, you use the test set to evaluate how well your model performs on unseen data.\n",
        "\n",
        "It simulates real-world data your model hasn't seen before.\n",
        "\n",
        "It helps detect overfitting .\n",
        "\n",
        "Never train your model or tune hyperparameters on the test set.\n"
      ],
      "metadata": {
        "id": "hE0Jiv7p2hLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "The most common and clean way to do this is using train_test_split from scikit-learn.\n",
        "\n",
        "1. Understand the Problem\n",
        "\n",
        "2. Collect and Explore Data\n",
        "\n",
        "3. Data Preprocessing\n",
        "\n",
        "4. Exploratory Data Analysis (EDA)\n",
        "\n",
        "5. Train a Model\n",
        "\n",
        "6. Evaluate the Model\n",
        "\n",
        "7. Deploy or Use the Model\n",
        "\n"
      ],
      "metadata": {
        "id": "RBneoUZv3JB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        " EDA helps you understand, clean, and prepare your data so your model doesn’t get fooled by bad or misleading information.\n",
        "\n",
        " Understand the Data Structure ,\n",
        "What are the features? ,What is the target variable?\n",
        "\n",
        "    Are the data types correct .\n",
        "\n",
        "    Find Missing or Corrupted Data\n",
        "Identify null/NaN values\n",
        "\n",
        "   Decide how to handle them .\n",
        "\n",
        "   Spot correlations, outliers, or patterns ,Understand feature importance or redundancy"
      ],
      "metadata": {
        "id": "QPNhPq6f4hhD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is correlation?\n",
        "\n",
        "Correlation is a statistical measure that describes the strength and direction of a relationship between two variables.\n",
        "Positive correlation means When one variable increases, the other tends to increase.\n",
        "Example: Height and weight often have a positive correlation.\n",
        "\n",
        "Negative correlation: When one variable increases, the other tends to decrease.\n",
        "Example: Time spent watching TV and exam scores might have a negative correlation.\n",
        "\n"
      ],
      "metadata": {
        "id": "dC9tnVO253N_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What does negative correlation mean?\n",
        "\n",
        "Negative correlation: When one variable increases, the other tends to decrease.\n",
        "Example: Time spent watching TV and exam scores might have a negative correlation.\n",
        "\n"
      ],
      "metadata": {
        "id": "LXh0fA8a6mBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14 .How can you find correlation between variables in Python?\n",
        "\n",
        "You can find the correlation between variables in Python using libraries like Pandas and NumPy.\n",
        "Using Pandas\n",
        "If you have your data in a DataFrame, this is the easiest way .\n",
        "\n",
        "Using Pandas\n",
        "If you have your data in a DataFrame, this is the easie.\n",
        "\n"
      ],
      "metadata": {
        "id": "R58XPVx26ygm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 15 . 5. What is causation? Explain difference between correlation and causation with an example.\n",
        "  \n",
        "   Causation refers to a relationship between two events where one event directly causes the other to happen .\n",
        "Correlation means two variables are related or move together — but one doesn’t necessarily cause the other.Causation means one variable causes a change in another.\n",
        "\n",
        "Example: Ice Cream Sales & Drowning Incidents\n",
        "Observation: As ice cream sales increase, so do drowning incidents.\n",
        "Correlation: There's a positive correlation between ice cream sales and drownings.\n"
      ],
      "metadata": {
        "id": "--h2xN0R9w6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        " An optimizer is an algorithm used to adjust the model's parameters  to minimize the loss function and improve model accuracy.\n",
        "\n",
        "  In simpler terms, the optimizer tells the model how to learn by tweaking the weights based on the error after each prediction.\n",
        "\n",
        "  Gradient Descent (GD) is type of optimizer ,its  Calculates the gradient of the loss function and updates weights in the opposite direction of the gradient to reduce error.\n",
        "\n",
        "  tochastic Gradient Descent (SGD) is similar to Gradient Descent, but updates weights using one sample at a time instead of the whole dataset.\n",
        "\n",
        "  tochastic Gradient Descent (SGD) is similar to Gradient Descent, but updates weights using one sample at a time instead of the whole dataset.\n",
        "\n",
        "  Momentum is adds a fraction of the previous weight update to the current update to accelerate convergence and reduce oscillations.\n",
        "\n"
      ],
      "metadata": {
        "id": "y575ExTj-J2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.What is sklearn.linear_model ?\n",
        "\n",
        "sklearn.linear_model gives you a toolkit of linear-based algorithms for both regression and classification. Easy to use and fits into Scikit-learn’s powerful pipeline system.\n",
        "sklearn.linear_model is a module in Scikit-learn that provides linear models for regression and classification tasks .\n"
      ],
      "metadata": {
        "id": "FHJkePuQ_p4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18 .What does model.fit() do? What arguments must be given?\n",
        "   \n",
        "   Model.fit() is a method used in machine learning libraries like Keras to train a model. It fits the model to the training data — essentially, it adjusts the model's weights based on the input data and target output.\n",
        "   Feeds the training data to the model.\n",
        "\n",
        "Calculates the error  between predicted and actual outputs."
      ],
      "metadata": {
        "id": "D8iseshwAJ9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What does model.predict() do? What arguments must be given?\n",
        "\n",
        " The model.predict() function in Scikit-learn is used to make predictions using a trained model. After you've trained your model with .fit(), you can use . predict() to input new data and get the model's output or guess.\n",
        "\n",
        " method predict(X)\t Purpose  Uses the trained model to make predictions based on new input  data ."
      ],
      "metadata": {
        "id": "VlBMoiIjA76-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20 .What are continuous and categorical variables?\n",
        "\n",
        "Continuous Variables are numeric variables that can take an infinite number of values within a given range.\n",
        "\n",
        " Characteristics:\n",
        "\n",
        " Measured, not counted\n",
        "\n",
        "Can be decimals or fractions\n",
        "\n",
        "Categorical Variables are represent groups or categories — not numerical in a meaningful sense.\n",
        "\n",
        " Characteristics:\n",
        "\n",
        "Can be text or numbers (but as labels)\n",
        "\n",
        "No inherent order (in nominal variables)\n",
        "\n"
      ],
      "metadata": {
        "id": "kx7LHzVdCymn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Scaling is the process of normalizing or standardizing the values of features in a dataset so that they are on a similar scale. This is important in machine learning because many algorithms, such as those that rely on distance metrics .If features are not scaled properly, some features may dominate others due to their larger range, leading to poor performance of the model. Prevents Bias in Algorithms.\n",
        "\n"
      ],
      "metadata": {
        "id": "N7LZcOgrDcBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22 .How do we perform scaling in Python?\n",
        "\n",
        "In Python, you can easily perform feature scaling using libraries like scikit-learn, which provides built-in tools for normalization and standardization. When applying scaling to new, unseen data, you must use the transform() method to ensure the new data is scaled based on the parameters computed from the training data ."
      ],
      "metadata": {
        "id": "d3H9hQEdEqXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is sklearn.preprocessing?\n",
        "\n",
        "sklearn.preprocessing is a module within scikit-learn that contains a collection of functions and classes for preprocessing data, such as scaling, encoding, transforming, and normalizing features. Proper preprocessing is an essential step in the machine learning pipeline, as it prepares the data in a way that is most suitable for modeling, helping algorithms learn more effectively and accurately."
      ],
      "metadata": {
        "id": "wjagPPRAFQmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24 .How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "To split data into training and testing sets in Python, you typically use the train_test_split function from the sklearn.model_selection module.\n",
        "\n",
        "This is a crucial step in building machine learning models because it allows you to evaluate your model’s performance on unseen data, helping prevent overfitting.\n",
        "\n",
        "Training Set- Used to fit/train your machine learning model.\n",
        "\n",
        "Testing Set- Used to evaluate how well the model generalizes to unseen data.\n",
        "\n",
        "Validation Set - Sometimes a third set is used for hyperparameter tuning ."
      ],
      "metadata": {
        "id": "0GhSE4e6GPri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25 .Explain data encoding?\n",
        "\n",
        "Data encoding is the process of converting categorical data (text or labels) into a numerical format that machine learning algorithms can understand and process. Machine learning models operate on numerical data. If you give them raw text, they can’t process it directly.\n",
        "\n",
        "Encoding ensures that -\n",
        "\n",
        "The algorithm interprets categories correctly."
      ],
      "metadata": {
        "id": "lU1ObkVxHFU8"
      }
    }
  ]
}